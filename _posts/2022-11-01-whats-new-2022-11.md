---
published: false
title: 'What we''ve been up to, November 2022'
---
What did we do those past 3 months? I didn't quite remember myself before deciding to write it up, so let's all dive in and see what's new.

# Vulnerable Road Users

In a [previous entry](/whats-new-2022-08/#pedestrians) I mentioned our work around Vulnerable Road Users (VRUs), which are a critical piece of our research. Over time we've worked a lot on pedestrians, but the past months we focused on "rides", mostly bicycles and E-scooters.

Rides are somewhat tricky to implement properly, as they're the result of the interaction of two bodies: the ride (vehicle) and the rider (character). To get a realistic and customizable behavior, both are implemented as [Skeletal Meshes](https://docs.unrealengine.com/4.27/en-US/WorkingWithContent/Types/SkeletalMeshes/), with the ride being driven by Unreal's vehicle framework (PhysX or Chaos), and the rider being animated by a home-made [Animation Blueprint](https://docs.unrealengine.com/5.0/en-US/animation-blueprints-in-unreal-engine), which actually works across *all* rides' types (e.g., bikes, scooter).

But when you have a wide range of rides *and* riders (e.g., child, adult), it starts to become quite complex to ensure the compatibility between all of those: a child and an adult aren't riding a scooter the same way. A lot of things can change: handle height, hands/feet position, elbow orientation, and so on.

And that's where Unreal "Data Asset" come into the picture. We can easily create assets that will hold all of the configuration values for a character, so that it perfectly fits our rides, and so we can easily reuse it. Since we have a rather large collection of characters, coming from various sources (e.g., Marketplace, CARLA), we've been able to build a library of Data Asset that can perfectly fit all of them into our rides. And Data Assets can even be edited at runtime, meaning it's super easy to fine tune every setting.

<video width="720" height="480" controls>
  <source type="video/mp4"
src="https://cdn.discordapp.com/attachments/725724080526852126/1034434419169173514/da_rider.mp4.mp4">
</video>

And as the video above shows: once you've defined your "rider" Data Asset, there's nothing stopping you from adding more than one rider on a single scooter! You just need to create Data Assets for both the "rider" and the "passenger", each having its own position offsets so that they both fit on the vehicle. This will be especially useful for an upcoming experiment, which aims at recreating complex and emerging car-VRU interactions.

Data Assets aren't particularily well documented, but they sure are a powerful Unreal feature. Since we discovered them for the use case mentioned above, we've already started using them in other parts of our tool.

# Unreal Engine 5

When [UE5.1's roadmap](https://portal.productboard.com/epicgames/1-unreal-engine-public-roadmap/tabs/80-unreal-engine-5-1-in-progress) got published, it motivated me enough to migrate our simulation platform from UE4.27 to UE5.

It wasn't a full migration from scratch: I had already prototyped things in the Early Access version, and most of our Marketplace products had already been updated to UE5. The main issue to solve was two-wheeled vehicles, as those work quite differently from PhysX to Chaos; and nearly all of the ones we use are custom made, so I couldn't rely on someone from the Marketplace just pushing an update!

In the end, vehicles were migrated rather easily, except for a couple minor issues... and a big one. I spent days narrowing down an issue where off-screen vehicles would just randomly go completely off-track. You can see from the video below: the red car passing by somehow does a 180Â° flip when off-screen and comes back the wrong way!

<video width="720" height="480" controls>
  <source type="video/mp4"
src="https://cdn.discordapp.com/attachments/725724080526852126/1009346667914481756/chaos8.mp4.mp4">
</video>

I got help from [Marco Ghislanzoni](https://www.youtube.com/c/marcoghislanzoni) to figure this one out, so many thanks to him. The issue was related to wheel colliders not being updating when the vehicle was not visible, which lead to lots more issues down the line. I reproduced the issue on the vehicle demo map, sent a bug report to Epic, and it now seems that this is solved in UE5.1! I'm not sure if my bug report helped, but in any case it's great to have that fixed.

In the end, I managed to run our [most complex UE4 scenario](/workflow-1) in UE5, which was my main goal. I still have so performance issue to figure out, as well as testing on our [nDisplay clusters](/ndisplay), but I'll wait for 5.1 to test that.

Since we have a very unusual "[forked template project](/version-control/#requirements)" workflow, with two active projects in development, the `master` branch on our repository is still using UE4. So merging Blueprint development done in master with changes in the UE5 branch isn't exactly easy nor fun, but at least we're moving closer to actually using Unreal Engine 5 in our driving simulation research.

At to conclude that UE5 section, I'll mention that Switchboard scripting is coming to UE5.1, which is a feature no-one is talking about (not even Epic), but which I'm very excited about: we'll be able to fully automate Switchboard, so no more needing to use the User Interface to launch the experiment, all that will be handled by background scripts. Experimenters will be able to focus on their work instead of having to learn the Switchboard UI!

# NEWMOB

We've mentioned [this](/whats-new-2022-08/#research-projects) [project](/workflow-1/) before, but this is still were most of our development time is spent.

The experiment's "training scenario" is now mostly done, and even though it's only for training, it's probably one of our most ambitious scenario yet. Around 15 minutes of driving, through various environment styles (e.g., rural, urban, industrial), with lots of interaction with VRUs.

The past few weeks were spent on optimization and polishing. Even though this experiment will use our largest driving simulator, we did a lot of testing on our mid-range one which is the only one available at the moment. Our unified workflow across all our cabins allow us to run any project on any of our platform, which is hugely beneficial during testing.

![newmob_sidewalks.jpg]({{site.baseurl}}/images/newmob_sidewalks.jpg)

We started using [Level Streaming](https://docs.unrealengine.com/5.0/en-US/level-streaming-in-unreal-engine/) to improve performance and stability (we were running out of GPU memory!). We're still figuring things out, but overall it's very positive. The picture above shows some recent rework: sidewalks. For quite some time now we've felt that our junctions were weird, but we couldn't quite put our finger on why. It turned out that our sidewalks didn't have a realistic geometry, which is not something obvious if you're not working with sidewalks in real life. Thankfully, [RoadRunner](https://mathworks.com/products/roadrunner.html) is so awesome that tweaking sidewalks takes a few seconds.

Next up in this project is the "main" scenario. From a design perspective, it will be quite similar to the one we've done for the training, except we're now all much more experienced in this workflow, so everything should be done much quicker. But we like to challenge ourselves, so we'll still try to add new and innovative things in it.

# Varjo

I moved to a new, much bigger, office; and one of the reason is to have more space to test and prototype with our XR tools. The headliner of which is the [Varjo XR-3](https://varjo.com/products/xr-3/).

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">A colleague helped me make this sweet &quot;<a href="https://twitter.com/hashtag/Varjo?src=hash&amp;ref_src=twsrc%5Etfw">#Varjo</a>-mobile&quot;. Now I can easily move our whole <a href="https://twitter.com/hashtag/XR?src=hash&amp;ref_src=twsrc%5Etfw">#XR</a> setup around campus for experiments, demos or simply prototyping in my office. <a href="https://t.co/lcRzMrYzug">pic.twitter.com/lcRzMrYzug</a></p>&mdash; Bertrand Richard (@brifsttar) <a href="https://twitter.com/brifsttar/status/1572861933103222784?ref_src=twsrc%5Etfw">September 22, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Our new Varjo-mobile will allow us to use our XR setup along with other scientific equipment. For instance, we plan on trying mixed reality on our [experimental seat](https://www.youtube.com/watch?v=IXMXGcjPyCI) used to study discomfort. And I'm strill planing on using mixed reality in our [main driving simulator]({{site.baseurl}}/images/simax.jpg) by throwing a green sheet over it and [chroma-keying](https://en.wikipedia.org/wiki/Chroma_key) all windows to display a virtual worlds over them. So stay tuned!

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">My new office has ample room for <a href="https://twitter.com/hashtag/VR?src=hash&amp;ref_src=twsrc%5Etfw">#VR</a> stuff, so it&#39;s time to experiment new things!<a href="https://twitter.com/hashtag/UnrealEngine?src=hash&amp;ref_src=twsrc%5Etfw">#UnrealEngine</a> + <a href="https://twitter.com/hashtag/Varjo?src=hash&amp;ref_src=twsrc%5Etfw">#Varjo</a> + <a href="https://twitter.com/hashtag/eScooter?src=hash&amp;ref_src=twsrc%5Etfw">#eScooter</a> + <a href="https://twitter.com/hashtag/Simulation?src=hash&amp;ref_src=twsrc%5Etfw">#Simulation</a> + <a href="https://twitter.com/hashtag/MixedReality?src=hash&amp;ref_src=twsrc%5Etfw">#MixedReality</a> = ? <a href="https://t.co/XhZtrT8sKp">pic.twitter.com/XhZtrT8sKp</a></p>&mdash; Bertrand Richard (@brifsttar) <a href="https://twitter.com/brifsttar/status/1554479118829363202?ref_src=twsrc%5Etfw">August 2, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Another Varjo-related development is scooter simulator. We're not quite sure we'll go forward with this, but it's really great to be able to prototype things with the XR-3: with depth occlusion and a scooter borrowed from a colleague, we've been able to simulate riding through a virtual world while seeing our very real body and vehicle. It looks very promising and opens up a whole lot of opportunities for all our researchers.

# Misc

Sometimes you get into the simulator, turn the key to start the vehicle, press the gas pedal and nothing happens. And then you're left wondering what possible thing could have gone wrong so that nothing is working anymore. To help debug this, and a whole lot of other thing, I added a simple "Input Values Debug" display on our UI.

Built using [UMG](https://docs.unrealengine.com/5.0/en-US/umg-ui-designer-for-unreal-engine/) and [Katan Charts](https://www.unrealengine.com/marketplace/en-US/product/kantan-charts) for the plots, it was actually fun (and easy) to implement, and I'm usually dreading any UI work. But UMG is really intuitive, and with Blueprint it's fairly clean and simple to get the desired values from the controller to the display. We have  tools outside Unreal to visualize inputs, but it's great to also have them in-engine to quickly get a glimpse of everything, as well as to help figure out where issues lie when debugging.

Input debug UI
Gitlab migration

# Marketplace

Bus, highway signs